{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6892966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87cfb9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Tipto\\\\End-to-End-Kidney-Disease-Classifier\\\\notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "219cf4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebf2d5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Tipto\\\\End-to-End-Kidney-Disease-Classifier'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f7b80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-02 23:19:31] Line: 30 | root - INFO - Entered read_yaml_file with file_path=config/config.yaml\n",
      "[2026-02-02 23:19:31] Line: 34 | root - INFO - YAML file loaded successfully: config/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from kidneyClassifier.constants import CONFIG_FILE_PATH\n",
    "from kidneyClassifier.utils.common import read_yaml_file\n",
    "config_contents = read_yaml_file(CONFIG_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a52eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train_transforms', 'test_transforms', 'base_model_config', 'updated_model_config'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_contents.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01af6066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from kidneyClassifier.logger import logging\n",
    "from kidneyClassifier.exception import KidneyException\n",
    "from kidneyClassifier.entity.config_entity import PrepareBaseModelConfig\n",
    "from  kidneyClassifier.entity.artifact_entity import PrepareBaseModelArtifact\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42546ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_transforms': [{'name': 'Resize', 'params': {'size': [256, 256]}},\n",
       "  {'name': 'RandomHorizontalFlip', 'params': {'p': 0.5}},\n",
       "  {'name': 'ToTensor', 'params': {}},\n",
       "  {'name': 'Normalize',\n",
       "   'params': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}],\n",
       " 'test_transforms': [{'name': 'Resize', 'params': {'size': [256, 256]}},\n",
       "  {'name': 'ToTensor', 'params': {}},\n",
       "  {'name': 'Normalize',\n",
       "   'params': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}],\n",
       " 'base_model_config': {'base_model_name': 'vgg16',\n",
       "  'base_model_weights': 'IMAGENET1K_V1'},\n",
       " 'updated_model_config': {'num_classes': 2,\n",
       "  'unfreeze_last_n_conv': 1,\n",
       "  'unfreeze_last_n_fc': 3,\n",
       "  'dropout_rate': 0.5,\n",
       "  'use_batch_norm': False}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad2ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_base_model_config = PrepareBaseModelConfig()\n",
    "def download_base_model(config: dict):\n",
    "    \"\"\"\n",
    "    Download a base model from torchvision and save it to the specified directory.\n",
    "\n",
    "    Returns:\n",
    "        Path: Path to the saved model file.\n",
    "\n",
    "    Raises:\n",
    "        KidneyException: If downloading or saving the model fails.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Entered download_base_model\")\n",
    "    try:\n",
    "        # extract base model configuration\n",
    "        base_model_config = config.get('base_model_config' , {})\n",
    "        model_name = base_model_config.get('base_model_name')\n",
    "        weights_name = base_model_config.get('base_model_weights')\n",
    "        \n",
    "        logging.info(f\"Model name: {model_name}, Weights: {weights_name}\")\n",
    "        \n",
    "        save_dir = Path(prepare_base_model_config.root_dir)\n",
    "        save_dir.mkdir(exist_ok = True , parents = True)\n",
    "        \n",
    "        # get the model class\n",
    "        model_class = getattr(models , model_name)\n",
    "        # Get the weights class\n",
    "        weights_enum = getattr(models, f\"{model_name.upper()}_Weights\")\n",
    "        weights = getattr(weights_enum, weights_name)\n",
    "        \n",
    "        # Download the model with pretrained weights\n",
    "        logging.info(f\"Downloading {model_name} with {weights_name} weights...\")\n",
    "        model = model_class(weights = weights)\n",
    "        # save the model\n",
    "        torch.save(\n",
    "            model.state_dict(),\n",
    "            prepare_base_model_config.base_model_file_path\n",
    "        )\n",
    "        logging.info(\n",
    "            f\"Base model saved successfully at: {prepare_base_model_config.base_model_file_path}\"\n",
    "        )\n",
    "        return prepare_base_model_config.base_model_file_path\n",
    "    \n",
    "    except AttributeError as e:\n",
    "        logging.error(f\"Model or weights not found: {model_name}, {weights_name}\")\n",
    "        raise KidneyException(f\"Invalid model name or weights: {e}\", sys)\n",
    "      \n",
    "    except Exception as e:\n",
    "        raise KidneyException(e , sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad76d617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-02 23:19:34] Line: 17 | root - INFO - Entered download_base_model\n",
      "[2026-02-02 23:19:34] Line: 24 | root - INFO - Model name: vgg16, Weights: IMAGENET1K_V1\n",
      "[2026-02-02 23:19:34] Line: 36 | root - INFO - Downloading vgg16 with IMAGENET1K_V1 weights...\n",
      "[2026-02-02 23:19:35] Line: 43 | root - INFO - Base model saved successfully at: artifacts\\prepare_base_model\\base_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifacts\\prepare_base_model\\base_model.pt\n"
     ]
    }
   ],
   "source": [
    "model_path = download_base_model(\n",
    "    config = config_contents\n",
    ")\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "491211e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_contents\n",
    "def update_model_for_classification():\n",
    "    \"\"\"\n",
    "    Update a base model for custom classification task by modifying the classifier\n",
    "    and freezing/unfreezing layers based on configuration.\n",
    "\n",
    "    Returns:\n",
    "        Path: Path to the saved updated model file.\n",
    "\n",
    "    Raises:\n",
    "        KidneyException: If updating or saving the model fails.\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info(f\"Entered update_model_for_classification\")\n",
    "    \n",
    "    try:\n",
    "        logging.info(f\"Entered update_base_model\")\n",
    "        # Extract configurations\n",
    "        base_model_config = config.get('base_model_config', {})\n",
    "        updated_model_config = config.get('updated_model_config', {})\n",
    "        \n",
    "        model_name = base_model_config.get('base_model_name')\n",
    "        weights_name = base_model_config.get('base_model_weights')\n",
    "        num_classes = updated_model_config.get('num_classes', 2)\n",
    "        unfreeze_last_n_conv = updated_model_config.get('unfreeze_last_n_conv', 0)\n",
    "        unfreeze_last_n_fc = updated_model_config.get('unfreeze_last_n_fc', 0)\n",
    "        dropout_rate = updated_model_config.get('dropout_rate', 0.5)\n",
    "        use_batch_norm = updated_model_config.get('use_batch_norm', False)\n",
    "        \n",
    "        logging.info(f\"Configuration - num_classes: {num_classes}, \"\n",
    "                    f\"unfreeze_last_n_conv: {unfreeze_last_n_conv}, \"\n",
    "                    f\"unfreeze_last_n_fc: {unfreeze_last_n_fc}\")\n",
    "        \n",
    "        # Set device\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        logging.info(f\"Using device: {device}\")\n",
    "        \n",
    "        # Load the base model architecture\n",
    "        model_class = getattr(models, model_name)\n",
    "        # dont need to weights again\n",
    "        model = model_class(weights = None) \n",
    "        \n",
    "        # Load the saved state dict\n",
    "        base_model_path = Path(\n",
    "            prepare_base_model_config.base_model_file_path\n",
    "        )\n",
    "        state_dict = torch.load(base_model_path, map_location = device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        logging.info(f\"Loaded model weights from: {base_model_path}\")\n",
    "        \n",
    "        # Freeze all layers initially\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        logging.info(\"All layers frozen initially\")\n",
    "        \n",
    "        # Unfreeze last N convolutional layers\n",
    "        if unfreeze_last_n_conv > 0:\n",
    "            conv_layers = list(model.features.children())\n",
    "            layers_to_unfreeze = conv_layers[-unfreeze_last_n_conv : ]\n",
    "            \n",
    "            for layer in layers_to_unfreeze:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = True\n",
    "            \n",
    "            logging.info(f\"Unfroze last {unfreeze_last_n_conv} convolutional layer(s)\")\n",
    "        \n",
    "        # Get the number of input features to the classifier\n",
    "        num_features = model.classifier[0].in_features\n",
    "        \n",
    "        # Create new classifier\n",
    "        if use_batch_norm:\n",
    "            new_classifier = nn.Sequential(\n",
    "                nn.Linear(num_features, 4096),\n",
    "                nn.ReLU(inplace = True),\n",
    "                nn.BatchNorm1d(4096),\n",
    "                nn.Dropout(p = dropout_rate),\n",
    "                nn.Linear(4096 , 4096),\n",
    "                nn.ReLU(inplace =True),\n",
    "                nn.BatchNorm1d(4096),\n",
    "                nn.Dropout(p = dropout_rate),\n",
    "                nn.Linear(4096, num_classes)\n",
    "            )\n",
    "        else:\n",
    "            new_classifier = nn.Sequential(\n",
    "                nn.Linear(num_features, 4096),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(p=dropout_rate),\n",
    "                nn.Linear(4096, 4096),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(p=dropout_rate),\n",
    "                nn.Linear(4096, num_classes)\n",
    "            )\n",
    "        \n",
    "        # Replace the classifier\n",
    "        model.classifier = new_classifier\n",
    "        logging.info(f\"Replaced classifier with {num_classes} output classes\")\n",
    "        \n",
    "        # Unfreeze last N fully connected layers\n",
    "        if unfreeze_last_n_fc > 0:\n",
    "            fc_layers = list(model.classifier.children())\n",
    "            linear_layers = [layer for layer in fc_layers if isinstance(layer, nn.Linear)]\n",
    "            layers_to_unfreeze = linear_layers[-unfreeze_last_n_fc : ]\n",
    "            \n",
    "            for layer in layers_to_unfreeze:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = True\n",
    "            \n",
    "            logging.info(f\"Unfroze last {unfreeze_last_n_fc} fully connected layer(s)\")\n",
    "        else:\n",
    "            # Unfreeze all classifier layers\n",
    "            for param in model.classifier.parameters():\n",
    "                param.requires_grad = True\n",
    "            logging.info(\"Unfroze all classifier layers\")\n",
    "        \n",
    "        # Log trainable parameters\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        logging.info(f\"Trainable parameters: {trainable_params:,} / {total_params:,} \"\n",
    "                    f\"({100 * trainable_params / total_params:.2f}%)\")\n",
    "        \n",
    "        \n",
    "        # Save the updated model\n",
    "        torch.save(\n",
    "            model.state_dict(), \n",
    "            prepare_base_model_config.updated_base_model_path\n",
    "        )\n",
    "        \n",
    "        logging.info(\n",
    "         f\"Updated model saved successfully at: {prepare_base_model_config.updated_base_model_path}\"\n",
    "        )\n",
    "        \n",
    "        # Save model architecture summary\n",
    "        summary_path = prepare_base_model_config.updated_model_architecture_summary_file_path\n",
    "        with open(summary_path, 'w') as f:\n",
    "            f.write(f\"Model: {model_name}\\n\")\n",
    "            f.write(f\"Weights: {weights_name}\\n\")\n",
    "            f.write(f\"Number of classes: {num_classes}\\n\")\n",
    "            f.write(f\"Dropout rate: {dropout_rate}\\n\")\n",
    "            f.write(f\"Use batch norm: {use_batch_norm}\\n\")\n",
    "            f.write(f\"Unfrozen conv layers: {unfreeze_last_n_conv}\\n\")\n",
    "            f.write(f\"Unfrozen FC layers: {unfreeze_last_n_fc}\\n\")\n",
    "            f.write(f\"Trainable parameters: {trainable_params:,} / {total_params:,}\\n\")\n",
    "            f.write(f\"\\nModel Architecture:\\n{model}\\n\")\n",
    "        \n",
    "        logging.info(f\"Model summary saved at: {summary_path}\")\n",
    "        \n",
    "        return prepare_base_model_config.updated_base_model_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error occurred while updating model: {e}\")\n",
    "        raise KidneyException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b0d09ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_base_model() -> PrepareBaseModelArtifact:\n",
    "    \"\"\"\n",
    "    Main orchestrator function that downloads the base model and then updates it\n",
    "    for the classification task.\n",
    "    \n",
    "    This function:\n",
    "    1. Calls download_base_model to download and save the pretrained model\n",
    "    2. Calls update_base_model with the downloaded model path to create the \n",
    "       updated model for classification\n",
    "    \n",
    "    Args:\n",
    "        config (dict): Configuration dictionary containing both base_model_config \n",
    "                      and updated_model_config.\n",
    "        base_model_dir (Union[str, Path]): Directory to save the base model.\n",
    "        updated_model_dir (Union[str, Path]): Directory to save the updated model.\n",
    "        device (Optional[str]): Device to load model on ('cpu', 'cuda', or None for auto).\n",
    "    \n",
    "    Returns:\n",
    "        Path: Path to the final updated model file.\n",
    "    \n",
    "    Raises:\n",
    "        KidneyException: If any step in the model preparation fails.\n",
    "    \"\"\"\n",
    "    logging.info(\"=\"*80)\n",
    "    logging.info(\"INITIATING BASE MODEL PREPARATION\")\n",
    "    logging.info(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Download base model\n",
    "        logging.info(\"Step 1/2: Downloading base model...\")\n",
    "        base_model_path = download_base_model(\n",
    "            config=config_contents,\n",
    "        )\n",
    "        logging.info(f\"Base model downloaded and saved at: {base_model_path}\")\n",
    "        # Step 2: Update base model for classification\n",
    "        logging.info(\"Step 2/2: Updating base model for classification...\")\n",
    "        updated_model_path = update_model_for_classification()\n",
    "        logging.info(f\"Model updated and saved at: {updated_model_path}\")\n",
    "        logging.info(\"=\"*80)\n",
    "        logging.info(\"BASE MODEL PREPARATION COMPLETED SUCCESSFULLY\")\n",
    "        logging.info(\"=\"*80)\n",
    "        \n",
    "        prepare_base_model_artifact = PrepareBaseModelArtifact(\n",
    "            base_model_file_path = prepare_base_model_config.base_model_file_path,\n",
    "            updated_base_model_file_path = prepare_base_model_config.updated_base_model_path,\n",
    "            updated_model_architecture_summary_file_path = prepare_base_model_config.updated_model_architecture_summary_file_path\n",
    "        )\n",
    "        return prepare_base_model_artifact\n",
    "    except Exception as e:\n",
    "        raise KidneyException(e , sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a8f445d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-02 23:19:35] Line: 24 | root - INFO - ================================================================================\n",
      "[2026-02-02 23:19:35] Line: 25 | root - INFO - INITIATING BASE MODEL PREPARATION\n",
      "[2026-02-02 23:19:35] Line: 26 | root - INFO - ================================================================================\n",
      "[2026-02-02 23:19:35] Line: 30 | root - INFO - Step 1/2: Downloading base model...\n",
      "[2026-02-02 23:19:35] Line: 17 | root - INFO - Entered download_base_model\n",
      "[2026-02-02 23:19:35] Line: 24 | root - INFO - Model name: vgg16, Weights: IMAGENET1K_V1\n",
      "[2026-02-02 23:19:35] Line: 36 | root - INFO - Downloading vgg16 with IMAGENET1K_V1 weights...\n",
      "[2026-02-02 23:19:36] Line: 43 | root - INFO - Base model saved successfully at: artifacts\\prepare_base_model\\base_model.pt\n",
      "[2026-02-02 23:19:36] Line: 34 | root - INFO - Base model downloaded and saved at: artifacts\\prepare_base_model\\base_model.pt\n",
      "[2026-02-02 23:19:36] Line: 36 | root - INFO - Step 2/2: Updating base model for classification...\n",
      "[2026-02-02 23:19:36] Line: 14 | root - INFO - Entered update_model_for_classification\n",
      "[2026-02-02 23:19:36] Line: 17 | root - INFO - Entered update_base_model\n",
      "[2026-02-02 23:19:36] Line: 30 | root - INFO - Configuration - num_classes: 2, unfreeze_last_n_conv: 1, unfreeze_last_n_fc: 3\n",
      "[2026-02-02 23:19:36] Line: 36 | root - INFO - Using device: cuda\n",
      "[2026-02-02 23:19:38] Line: 49 | root - INFO - Loaded model weights from: artifacts\\prepare_base_model\\base_model.pt\n",
      "[2026-02-02 23:19:38] Line: 54 | root - INFO - All layers frozen initially\n",
      "[2026-02-02 23:19:38] Line: 65 | root - INFO - Unfroze last 1 convolutional layer(s)\n",
      "[2026-02-02 23:19:38] Line: 96 | root - INFO - Replaced classifier with 2 output classes\n",
      "[2026-02-02 23:19:38] Line: 108 | root - INFO - Unfroze last 3 fully connected layer(s)\n",
      "[2026-02-02 23:19:38] Line: 118 | root - INFO - Trainable parameters: 119,554,050 / 134,268,738 (89.04%)\n",
      "[2026-02-02 23:19:39] Line: 128 | root - INFO - Updated model saved successfully at: artifacts\\prepare_base_model\\base_model_updated.pth\n",
      "[2026-02-02 23:19:39] Line: 145 | root - INFO - Model summary saved at: artifacts\\_architecture_summary.txt\n",
      "[2026-02-02 23:19:39] Line: 38 | root - INFO - Model updated and saved at: artifacts\\prepare_base_model\\base_model_updated.pth\n",
      "[2026-02-02 23:19:39] Line: 39 | root - INFO - ================================================================================\n",
      "[2026-02-02 23:19:39] Line: 40 | root - INFO - BASE MODEL PREPARATION COMPLETED SUCCESSFULLY\n",
      "[2026-02-02 23:19:39] Line: 41 | root - INFO - ================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PrepareBaseModelArtifact(base_model_file_path='artifacts\\\\prepare_base_model\\\\base_model.pt', updated_base_model_file_path='artifacts\\\\prepare_base_model\\\\base_model_updated.pth', updated_model_architecture_summary_file_path='artifacts\\\\_architecture_summary.txt')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initiate_base_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ae6d07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kidney",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
